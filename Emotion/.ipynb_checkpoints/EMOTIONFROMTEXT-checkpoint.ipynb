{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473a0134-e8c2-459b-94c1-64330403a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detects emotions from text\n",
    "#Created by S. Biswas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed84f5c0-14ee-486e-8a34-ce5dd5939d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        sadness\n",
      "1        sadness\n",
      "2          anger\n",
      "3           love\n",
      "4          anger\n",
      "          ...   \n",
      "15995    sadness\n",
      "15996    sadness\n",
      "15997        joy\n",
      "15998      anger\n",
      "15999    sadness\n",
      "Name: Emotion, Length: 15999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.txt', sep=';', names=['Sentence', 'Emotion'], encoding='UTF8')\n",
    "#data cleaning\n",
    "df_train = df_train[df_train['Sentence'] != '']\n",
    "df_train = df_train.dropna()\n",
    "df_train = df_train.drop_duplicates()\n",
    "# df_train = df_train[df_train['Sentence'] != '']\n",
    "print(df_train['Emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f1b7e7-de1c-4fc0-b664-a2433cd3b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['length'] = [len(sen) for sen in df_train['Sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ecf010-c3dd-4c35-b6f0-47730926eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4d94c7-ef3b-4047-8f7c-9cc5b891acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        4\n",
      "1        4\n",
      "2        0\n",
      "3        3\n",
      "4        0\n",
      "        ..\n",
      "15995    4\n",
      "15996    4\n",
      "15997    2\n",
      "15998    0\n",
      "15999    4\n",
      "Name: Emotions, Length: 15999, dtype: int64\n",
      "0        sadness\n",
      "1        sadness\n",
      "2          anger\n",
      "3           love\n",
      "4          anger\n",
      "          ...   \n",
      "15995    sadness\n",
      "15996    sadness\n",
      "15997        joy\n",
      "15998      anger\n",
      "15999    sadness\n",
      "Name: Original_Emotion, Length: 15999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sea\n",
    "# sea.countplot(x=df_train['Emotion'])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "df_train['Emotions'] = lb.fit_transform(df_train['Emotion'])\n",
    "print(df_train['Emotions'])\n",
    "df_train['Original_Emotion'] = lb.inverse_transform(df_train['Emotions'])\n",
    "print(df_train['Original_Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7f0a10-6b83-456b-83ca-3283d41c95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2f097f-b838-4b8e-a6f3-489e1203c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "df_train['Cleaned_Sentence'] = df_train['Sentence'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "df_train['Cleaned_Sentence'] = df_train['Cleaned_Sentence'].apply(lambda x: x.lower())\n",
    "df_train['Final_Cleaned_Sentence'] = df_train['Cleaned_Sentence'].apply(lambda x: ' '.join(stemmer.stem(word) for word in x.split() if word not in stopwords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7d58df-d735-4f83-a673-bea51b72345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>length</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Original_Emotion</th>\n",
       "      <th>Cleaned_Sentence</th>\n",
       "      <th>Final_Cleaned_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel Humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>didnt feel humili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>go feel hopeless damn hope around someon care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>im grab minut post feel greedi wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>love</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>ever feel nostalg fireplac know still properti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>feel grouchi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Emotion  length  \\\n",
       "0                            i didnt feel Humiliated  sadness      23   \n",
       "1  i can go from feeling so hopeless to so damned...  sadness     108   \n",
       "2   im grabbing a minute to post i feel greedy wrong    anger      48   \n",
       "3  i am ever feeling nostalgic about the fireplac...     love      92   \n",
       "4                               i am feeling grouchy    anger      20   \n",
       "\n",
       "   Emotions Original_Emotion  \\\n",
       "0         4          sadness   \n",
       "1         4          sadness   \n",
       "2         0            anger   \n",
       "3         3             love   \n",
       "4         0            anger   \n",
       "\n",
       "                                    Cleaned_Sentence  \\\n",
       "0                            i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned...   \n",
       "2   im grabbing a minute to post i feel greedy wrong   \n",
       "3  i am ever feeling nostalgic about the fireplac...   \n",
       "4                               i am feeling grouchy   \n",
       "\n",
       "                              Final_Cleaned_Sentence  \n",
       "0                                  didnt feel humili  \n",
       "1  go feel hopeless damn hope around someon care ...  \n",
       "2               im grab minut post feel greedi wrong  \n",
       "3     ever feel nostalg fireplac know still properti  \n",
       "4                                       feel grouchi  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1d4d6e-edb5-4f02-be6c-c9d0ce48bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train['Final_Cleaned_Sentence'], df_train['Emotion'], test_size= 0.2 , random_state=42 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2c9ff4-14d0-47dc-af31-6bf9a568af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfv = TfidfVectorizer()\n",
    "x_train_tfidf = tfidfv.fit_transform(x_train)\n",
    "x_test_tfidf = tfidfv.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f23e9409-2471-4d73-ab2f-8bcf19d23f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====MultinomialNB======\n",
      "\n",
      "=====0.6590625======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.95      0.32      0.48       439\n",
      "        fear       0.88      0.23      0.37       375\n",
      "         joy       0.58      0.98      0.73      1027\n",
      "        love       1.00      0.03      0.05       303\n",
      "     sadness       0.72      0.91      0.80       950\n",
      "    surprise       1.00      0.02      0.04       106\n",
      "\n",
      "    accuracy                           0.66      3200\n",
      "   macro avg       0.85      0.42      0.41      3200\n",
      "weighted avg       0.76      0.66      0.59      3200\n",
      "=====\n",
      "=====SVC======\n",
      "\n",
      "=====0.815625======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.79      0.83       439\n",
      "        fear       0.84      0.73      0.78       375\n",
      "         joy       0.75      0.94      0.83      1027\n",
      "        love       0.82      0.37      0.51       303\n",
      "     sadness       0.87      0.90      0.89       950\n",
      "    surprise       0.82      0.47      0.60       106\n",
      "\n",
      "    accuracy                           0.82      3200\n",
      "   macro avg       0.83      0.70      0.74      3200\n",
      "weighted avg       0.82      0.82      0.80      3200\n",
      "=====\n",
      "=====RandomForestClassifier======\n",
      "\n",
      "=====0.849375======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.82      0.87      0.84       439\n",
      "        fear       0.84      0.85      0.84       375\n",
      "         joy       0.83      0.90      0.86      1027\n",
      "        love       0.82      0.59      0.69       303\n",
      "     sadness       0.91      0.89      0.90       950\n",
      "    surprise       0.72      0.74      0.73       106\n",
      "\n",
      "    accuracy                           0.85      3200\n",
      "   macro avg       0.82      0.80      0.81      3200\n",
      "weighted avg       0.85      0.85      0.85      3200\n",
      "=====\n",
      "=====LogisticRegression======\n",
      "\n",
      "=====0.8240625======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.78      0.83       439\n",
      "        fear       0.85      0.72      0.78       375\n",
      "         joy       0.76      0.94      0.84      1027\n",
      "        love       0.83      0.46      0.59       303\n",
      "     sadness       0.88      0.92      0.90       950\n",
      "    surprise       0.74      0.46      0.57       106\n",
      "\n",
      "    accuracy                           0.82      3200\n",
      "   macro avg       0.82      0.71      0.75      3200\n",
      "weighted avg       0.83      0.82      0.82      3200\n",
      "=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sauman/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = {\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'SVC':SVC(),\n",
    "    'RandomForestClassifier' : RandomForestClassifier(),\n",
    "    'LogisticRegression' : LogisticRegression(),   \n",
    "}\n",
    "for name, cls in classifier.items():\n",
    "    cls.fit(x_train_tfidf, y_train)\n",
    "    y_pred = cls.predict(x_test_tfidf)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"====={name}======\\n\")\n",
    "    print(f\"====={acc}======\\n\")\n",
    "    rep = classification_report(y_test, y_pred)\n",
    "    print(f\"======{rep}=====\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750911c-0923-4e43-9c11-fd5adf7e3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7105effe-7c10-47df-b2a9-e462c9a7da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sauman/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming stemmer and tfidfv are already defined and trained\n",
    "lg = LogisticRegression()\n",
    "lg.fit(x_train_tfidf, y_train)\n",
    "\n",
    "def clean_data_for_predict(text):\n",
    "    clean_text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    t = clean_text.lower()  # Apply lowercasing on clean_text\n",
    "\n",
    "    # Ensure stemmer is called correctly\n",
    "    t = ' '.join(stemmer.stem(w) for w in t.split())\n",
    "    return t\n",
    "\n",
    "def predict_emotion(text):\n",
    "    text = clean_data_for_predict(text)\n",
    "    v = tfidfv.transform([text])  # Wrap text in a list to form a 2D array\n",
    "    \n",
    "    label = lg.predict(v)[0]  # Get the predicted label directly\n",
    "    emo = lb.inverse_transform(lg.predict(v))[0]\n",
    "    return emo, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef01a4aa-3090-47b3-98d1-251a9e8b6815",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: ['love']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI love you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m v \u001b[38;5;241m=\u001b[39m tfidfv\u001b[38;5;241m.\u001b[39mtransform([text])  \u001b[38;5;66;03m# Wrap text in a list to form a 2D array\u001b[39;00m\n\u001b[1;32m     17\u001b[0m label \u001b[38;5;241m=\u001b[39m lg\u001b[38;5;241m.\u001b[39mpredict(v)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get the predicted label directly\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m emo \u001b[38;5;241m=\u001b[39m \u001b[43mlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emo, label\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:161\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(y, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)))\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[1;32m    162\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[y]\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: ['love']"
     ]
    }
   ],
   "source": [
    "predict_emotion(\"I love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c81db3e-15f1-43c8-8870-4794b6503644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def cleaning_data(df, col, voc_size, max_len):\n",
    "    stemmer = PorterStemmer()\n",
    "    corpus = []\n",
    "    one_hot_code = []\n",
    "    for x in df[col]:\n",
    "        x = re.sub('[^a-zA-Z]', ' ', x)\n",
    "        x = x.lower()\n",
    "        x = x.split()\n",
    "        clean_words = []\n",
    "        for y in x:\n",
    "            if y not in stopwords:\n",
    "                clean_words.append(stemmer.stem(y))\n",
    "        corpus.append(' '.join(clean_words)) \n",
    "\n",
    "                \n",
    "    for line in corpus:       \n",
    "        encoded = one_hot(line, voc_size)\n",
    "        one_hot_code.append(encoded)\n",
    "\n",
    "    one_hot_code_padded = pad_sequences(one_hot_code, maxlen=max_len, padding='pre')\n",
    "    return one_hot_code_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f95a4c9-3436-4524-92a3-50f0db26cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...  3889  9998  3740]\n",
      " [    0     0     0 ...  2656  9684  3802]\n",
      " [    0     0     0 ...  9998 10307  5084]\n",
      " ...\n",
      " [    0     0     0 ...  9082  8927  4856]\n",
      " [    0     0     0 ... 11966  4999  5699]\n",
      " [    0     0     0 ...  9998  6877  8658]]\n",
      "15999\n",
      "15999\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x_train = cleaning_data(df_train, 'Sentence', 12000, 3000)\n",
    "print(x_train)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(df_train['Emotion'])\n",
    "y_train = to_categorical(y_train_encoded)\n",
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b9fd8-4195-4846-8181-d97502471917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Dropout, LSTM, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Assuming y_train contains class labels (0-5 for 6 classes)\n",
    "# One-hot encode y_train if it is not already\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(df_train['Emotion'])\n",
    "y_train = to_categorical(y_train_encoded)  \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=12000, output_dim=150, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128, return_sequences=True))  \n",
    "model.add(LSTM(64, return_sequences=False))  \n",
    "# model.add(Dense(64, activation='sigmoid')) \n",
    "model.add(Dense(6, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed06c1-6f08-45af-9a72-a5c2c65332b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae37a5-8f13-490b-94ee-81a78f3d45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
